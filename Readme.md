
# í”„ë¡œì íŠ¸: ETL ê¸°ì´ˆ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•
## Architecture
ğŸ“¦src
 â”£ ğŸ“‚ETL_func
 â”ƒ â”£ ğŸ“œextract.py
 â”ƒ â”£ ğŸ“œload.py
 â”ƒ â”£ ğŸ“œtransform.py
 â”ƒ â”— ğŸ“œ__init__.py
 â”— ğŸ“œmodel.py

## ê°œìš”
- ì£¼ì–´ì§„ ì„œë²„(url)ì— ì£¼ê¸°ì ìœ¼ë¡œ ìƒì„±ë˜ê³  ìˆëŠ” ì„ì˜ì˜ ë¡œê·¸ë°ì´í„°ë¥¼ ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ í™œìš©í•˜ì—¬ ì¶”ì¶œí•˜ê³ ,
- ì´ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì••ì¶•ë³€í™˜í•˜ì—¬ AWS S3 ê°ì²´ë¡œ í´ë”í™”í•˜ì—¬ ì €ì¥í•˜ëŠ” í”„ë¡œì íŠ¸

## ìˆ˜í–‰ ì ˆì°¨
- 0. ë°ì´í„° ì¶”ì¶œ
    - urlë¡œë¶€í„° ê°€ì ¸ì˜¨ ë°ì´í„°ì—ì„œ 'data' ë¶€ë¶„ì´ ë°”ì´íŠ¸í˜•íƒœë¡œ ì•”í˜¸í™” ë˜ì–´ìˆìŒ
    ```python
    # ETL_func/extract.py
    def extract_logs(): # ë°ì´í„° ë°›ì•„ì˜¤ê¸°
    ```
- 1. ë°ì´í„° ë³€í™˜
    - ì¶”ì¶œì„ í†µí•´ ë°›ì•„ì˜¨ dataì— ëŒ€í•´ ì•”í˜¸í™” ë° ë³µí˜¸í™” ì‘ì—… ìˆ˜í–‰
        - fernet ì‚¬ìš©, 'utf-8' encoding ë°©ì‹
        ```python
        # ETL_func/transform.py
        def transform_logs(data):
            key = bytes(os.environ.get('f_key'), encoding='utf-8')
            fernet = Fernet(key)
            """ ì´í•˜ ì½”ë“œ ìƒëµ """
        ```
    - ë¡œê·¸ë°ì´í„°ëŠ” jsoní˜•ì‹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ìˆìŒ
        - 'user_id' : b64uuid ëª¨ë“ˆ í™œìš©í•˜ì—¬ 64ìë¦¬ -> 44ìë¦¬ë¡œ ê¸¸ì´ ì¶•ì†Œ
        - 'method' : 'GET' ì´ë‚˜ 'POST' -> mapping í™œìš©í•˜ì—¬ 1ê³¼ 2ë¡œ êµ¬ë¶„í•˜ì—¬ í¬ê¸° ì¶•ì†Œ
        - 'inDate' : ì •ë³´ì˜ ì†ì‹¤ì—†ì´ ê¸°ì¡´ì˜ ë‚ ì§œ í˜•ì‹ì„ ë¬¸ìì—´ í˜•ì‹ìœ¼ë¡œ ì••ì¶•
        ```python
        # ETL_func/transform.py
        def b64_change_44(user_id): # id
        def method_mapping(method): # method
        def short_date(inDate): # inDate
        
        def compress_log(log): # ë¬¸ìì—´ ì••ì¶•í•˜ì—¬ ë°˜í™˜
            tmp = log.copy()
            tmp['user_id'] = b64_change_44(tmp['user_id'])
            tmp['method'] = method_mapping(tmp['method'])
            tmp['inDate'] = short_date(tmp['inDate'])
            return tmp
        ```
    
- 2. ë°ì´í„° ì ì¬
    - AWS IAM ê³„ì •ì˜ ì•¡ì„¸ìŠ¤í‚¤ë¥¼ ìƒì„±, S3 ë²„í‚·ì„ ë§Œë“¤ì–´ ë³€í™˜ëœ ë°ì´í„°ë¥¼ ì ì¬
        - ì ì¬ ë°©ì‹ì€ ë°ì´í„°ì˜ inDateì˜ ì‹œë‹¨ìœ„ ì •ë³´ê¹Œì§€ êµ¬ë¶„í•˜ì—¬ gzip ì ìš© í›„ ì ì¬
        ```python
        # ETL_func/load.py
        def get_s3_key(in_date, file_name): # í‚¤ ì§€ì •
        def upload_to_s3(in_date, file_name, log_data): # gzipì••ì¶• ë° ì—…ë¡œë“œ, get_s3_key í˜¸ì¶œ
        def load_logs(logs_data): # ë‚ ì§œ-ì‹œë‹¨ìœ„ë¡œ ë°ì´í„° ë¶„ë¥˜, upload_to_s3 í˜¸ì¶œ
        ```
- 3. ìŠ¤ì¼€ì¤„ë§ ì ìš©
    - ì›ë³¸ ë°ì´í„°ëŠ” 3ë¶„ì— 1ë²ˆì”© 100ê°œì˜ ë°ì´í„°ê°€ ê°±ì‹ ë¨
    - 3ë¶„ë§ˆë‹¤ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ë„ë¡ apscheduler ê°ì²´ êµ¬í˜„
        - cronì„ í™œìš©í•˜ì—¬ ì›ë³¸ì´ ìƒì„±ë˜ëŠ” ì§í›„ ì‹œê°„ëŒ€ë¡œ ì§€ì •í•˜ë©´ ì†ì‹¤ ìµœì†Œí™” ê°€ëŠ¥
        - ì¢…ë£ŒëŠ” í˜„ì¬ ìˆ˜ë™ ctrl+c í‚¤ì…ë ¥.. ê°œì„  í•„ìš”í•œ ë¶€ë¶„
        ```python
        def ETL(): # ìŠ¤ì¼€ì¤„ëŸ¬ì— ë“¤ì–´ê°ˆ ETL ì‘ì—…
        def main(): # ë©”ì¸
            sched = BackgroundScheduler()
            # 3ì˜ ë°°ìˆ˜ ë¶„ì˜ 5ì´ˆ ë§ˆë‹¤ ETL ì‘ì—… í˜¸ì¶œ
            sched.add_job(ETL, 'cron', minute='0,3,6,9,12,15,18,21,24,27,30,33,36,39,42,45,48,51,54,57', second='5', id='test_cron')
            sched.start()
        ```

## ìˆ˜í–‰ ê²°ê³¼
- AWS EC2 ê³„ì •ìœ¼ë¡œ ì½˜ì†” ë¡œê·¸ì¸í•˜ì—¬ S3 ë²„í‚· í™•ì¸
- í´ë”ëª…, íŒŒì¼ëª… í™•ì¸
   ![image](https://user-images.githubusercontent.com/59263935/226332246-986177d4-7e0a-4ffa-9862-cabc29710d79.png)
   ![image](https://user-images.githubusercontent.com/59263935/226332349-e6ef2ca6-915a-4ad8-8e3a-fed2ca7272d8.png)



### ê°œì„ í•  ë¶€ë¶„
- AWS Athena ë¡œ ê²€ìƒ‰í•˜ëŠ” ê²ƒê¹Œì§€ ì™„ì„±í•˜ì§€ ëª»í•¨. í•™ìŠµ ì¤‘..
- ìŠ¤ì¼€ì¤„ë§ ì¶”ê°€ í•™ìŠµ í•„ìš”
